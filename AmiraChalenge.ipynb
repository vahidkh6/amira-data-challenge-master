{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amira Data Challenge - Vahid Khanagha\n",
    "The task is to use predictions from differnt ASR system to describe how students have pronounced the words in the stories they read. A naive solution is to take ASR outputs as perfect and score the students based on ASR predictions. Two main arguments against this approach can be:\n",
    "\n",
    "- what if student made an error but ASR Language Model (LM) fixed it\n",
    "- what if the student didn't make an error, but ASR Acoustic Model (AM) failed to correctly transcribe (due to acoustical conditions, accent, etc)\n",
    "\n",
    "\n",
    "Some of the related open questions to think about:\n",
    "\n",
    "- How are the ASR sysyems trained? Do they have a Language Model (LM) trained on in-domain text?\n",
    "- Is it good to have a LM trained with in-domaon data? Won't it correct student errors? without it, won't the ASR system performance be poor? \n",
    "\n",
    "For the task at hand, we can't have the answer to these questions, nor we can make a change to the features we have. So we move on to use these features to build a model. As the naive approach does not seem to be reasonable, we opt for using ensemble learning, to take the opinions of all the four ASR systems into account, hoping that they are meaningfully different systems. \n",
    "\n",
    "## Data exploration:\n",
    "- Each row of `activity_data_100.csv` contains an `expected text` field (which is the same as `golden_transcripts`) which we take as **target** field (so we don't use`story.csv`). We use `expected text` field to create the set of words the student are expected to have pronounced correctly.\n",
    "- The corresponding ASR systems' predictions seem not to be always aligned with the `expected text` field and they have some extra words before and after the relevant phrase.\n",
    "- human annotations in `utterance.csv` seem to mark errors with a `abcabc` prefix. But a closer look reveals there seem to be other errors as well: some substitutions and some deletions (compared to the words in `expected text`). We start by looking for both types of `erros`: `substitutions` and `deletions`, and will decide later if `deletions` could be merged or even dropped. \n",
    "\n",
    "- The confidence scores from the ASR systems can be more insightful than their ultimate predictions: in the case that one student made an error and ASR LM fixed it, confidence should be low and varry between different systems. This can be an indication of the hidden error.\n",
    "In the case that student read correctly, ASR made a mistake (AM or LM), ASR systems might be in disagreement, which could be used to discard the false positve (of an error).\n",
    "In the case that, student read correctly, ASR systems all detected correctly  with high confidence, we may assume no error is made.\n",
    "\n",
    "\n",
    "## Problem definition\n",
    "A classifier, classifying each word in the set of ground truth words as `correctly` pronounced, pronounced with `error`, or with `deletion`.\n",
    "\n",
    "\n",
    "## Alignment of ASR predictions with story phrases\n",
    "As mentioned above, ASR predictions are not perfectly aligned with the target text in `expected text` field. There are some rows in `activity_data_100.csv`, where `kaldi_text` has some extra words before and after the part that corresponds to the target text. Fort instance, in the below example, `kaldi text` seeem to completely cover the story text in the `expected text` field, but there are several words before and after the phrase of interest.\n",
    "\n",
    "- story text:  `he even called the other kids names and stole their snacks`\n",
    "- kaldi text:  `he stole the led called skid he even called the other kids names and stole their snacks other kids`\n",
    "\n",
    "This might be because ASR systems are fed with audio that covered a bit of audio before and after the exact time the `expected text` was uttered.\n",
    "In order to use ASR systems outputs for the task at hand, we first need to align these utterances. Only then we can propperly use the confidence scores to perform pronounciation assesment.\n",
    "\n",
    "We use the edit distance sequence matching approach to make this alignment. The sequence matcher, matches the two sequences such that the total number of mismatches are minimized. This seems to be a reasonable approach for finiding out how best ASR ouputs can be aligned to the phrases in `expected text`.\n",
    "\n",
    "## Alignment of word-level human annotations, to the aligned texts\n",
    "Once ASR outputs are trimmed to align with `expected text`, we face a second sequence matching problem in using human annotations to build a classifier. Human annotations are made on word level and can only be tied to the activites df through `activityID`. But how do we pair the words in  `utterance.csv` with the words from ASR system (matched to `expected text`)?\n",
    "\n",
    "Once again we use edit-distance-based sequence matching to find the best possible alignment between all of the words annotated for each `activityID` and the words from ASR system outputs. \n",
    "This time, we face a challenge that some of the words that should be aligned, are not actually matching. For instance, `names` might be annotated as `abcabcname`. For this reason, a more relaxed definition of \"matching\" is used for edit-distance-based sequence mathcing. In this case, we take \"partially\" equivalent strings to be considered as \"matches\" and be aligned with each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install edit_distance pandas matplotlib numpy sklearn\n",
    "import ast\n",
    "import string\n",
    "import edit_distance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def normalize_text(txt):\n",
    "    \"\"\"basic text normalization operations\n",
    "    ------\n",
    "    inputs: \n",
    "        txt(str) : a string to be standardized\n",
    "    returns:\n",
    "        new_txt(str): standardized text\n",
    "    \"\"\"\n",
    "    # remove capitalization\n",
    "    new_txt = txt.strip().lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    new_txt = new_txt.translate(str.maketrans('', '', string.punctuation))\n",
    "    return new_txt\n",
    "\n",
    "def normalize_df_column(col_str):\n",
    "    \"\"\" a lambda function, to apply normalize_text to different columns of \n",
    "    the act_df. Some columns are string representations of lists and\n",
    "    dictionaries that are converted to the original data type.\n",
    "    Other columns are plain text, and are normalized.\n",
    "    \n",
    "    Inputs: col_str(str) : the value from one column that needs to be standardized\n",
    "    \"\"\"\n",
    "    new_val = \"\"\n",
    "    if isinstance(col_str, str):  #some nan values exist\n",
    "        if '[' in col_str:  # [ is taken as an indication of a data structure\n",
    "            new_val = ast.literal_eval(col_str)\n",
    "        else:\n",
    "            new_val = normalize_text(col_str)\n",
    "    return new_val\n",
    "\n",
    "def align_with_gold(ref, hyp, confids):\n",
    "    \"\"\"\n",
    "    Takes SR output and alignes it with the refference (expected text) using\n",
    "    edit_distance.\n",
    "    ----\n",
    "    Inputs:\n",
    "        ref(str): a string containing expected text\n",
    "        hyp(str): a string containing ASR system output\n",
    "        confids[list]: a list of lists, or tuples. The list is indexed in parallel\n",
    "            with hyp, and for each word in hyp, it contains a [word, confidence] pair of\n",
    "            info\n",
    "        targets[dict]: a dictionary with all word in ref as keys, and the values that contain\n",
    "            the info about whether the word was:\n",
    "                - correctly detected ==> confidenc_Value (positive float value)\n",
    "                - deleted ==> -4 (large negatiev value)\n",
    "                - substituted ==> - confidence_value\n",
    "            substituted by the ASR system. (negative float value)\n",
    "            ex: {'adam': 0.98, 'was': -4, \"sad\": -0.75} means:\n",
    "                 'adam' is correctly detected, 'was' is deleted, \n",
    "                  and 'sad' is replaced (we don't care with what for now)\n",
    "    \n",
    "    \"\"\"\n",
    "    ref_list = ref.split(\" \")\n",
    "    hyp_list = hyp.split(\" \")\n",
    "    _, _, opcodes = edit_distance.edit_distance_backpointer(ref_list, hyp_list)\n",
    "    targets = {}\n",
    "    for op in opcodes:\n",
    "        if op[0] != 'insert':\n",
    "            if op[0] == 'equal':\n",
    "                targets[ref_list[op[1]]] = round(confids[op[3]][1], 2)\n",
    "            elif op[0] == 'replace':\n",
    "                if len(confids) > op[3]:\n",
    "                    targets[ref_list[op[1]]] = - round(confids[op[3]][1], 2)\n",
    "                else:\n",
    "                    # edge case when asr returns no word at all (no confidence)\n",
    "                    targets[ref_list[op[1]]] = -4 # it's a deletion \n",
    "            else:\n",
    "                targets[ref_list[op[1]]] = -4 # deletion\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not using story.csv and activities.csv. Allign records using activity_data_100.csv\n",
    "act_df = pd.read_csv('activity_data_100.csv')\n",
    "utt_df = pd.read_csv('utterance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all text columns\n",
    "# + Change data type of cols with stringed data strucuture to usable format\n",
    "norm_cols = ['kaldi_text', 'kaldi_transcription', 'google_output',\n",
    "             'pocketsphinx_transcript', 'pocketsphinx_word_confidence',\n",
    "             'amazon_transcript', 'amazon_word_confidence', 'amazon_word_lapse',\n",
    "             'amazon_frame_interval', 'expected text', 'golden transcript']\n",
    "for c in norm_cols:\n",
    "    act_df[c] = act_df[c].apply(lambda x: normalize_df_column(x))\n",
    "\n",
    "# prepare google columns\n",
    "# not sure what's the difference between google_confidence_0 and google_confidence_1. They look the same\n",
    "act_df['google_confidence_0'] = act_df['google_output'].apply(lambda x: x[1])\n",
    "act_df['google_confidence_1'] = act_df['google_output'].apply(lambda x: x[2])\n",
    "act_df['google_output'] = act_df['google_output'].apply(lambda x: normalize_text(x[0]))\n",
    "\n",
    "# prepare kaldi confidence scores\n",
    "act_df['kaldi_confids'] = act_df['kaldi_transcription'].apply(lambda x: [[xk['word'], xk['confidence']] for xk in x])\n",
    "\n",
    "# align ASR outputs with \"expected text\" field and generate word-level scores\n",
    "act_df['google_scores'] = act_df.apply(lambda row: align_with_gold(row['expected text'],\n",
    "                                                                   row['google_output'],\n",
    "                                                                   row['google_confidence_1']),axis=1)\n",
    "act_df['amazon_scores'] = act_df.apply(lambda row: align_with_gold(row['expected text'],\n",
    "                                                                   row['amazon_transcript'],\n",
    "                                                                   row['amazon_word_confidence']), axis=1)\n",
    "act_df['pocketsphinx_scores'] = act_df.apply(lambda row: align_with_gold(row['expected text'],\n",
    "                                                                         row['pocketsphinx_transcript'],\n",
    "                                                                         row['pocketsphinx_word_confidence']), axis=1)\n",
    "act_df['kaldi_scores'] = act_df.apply(lambda row: align_with_gold(row['expected text'],\n",
    "                                                                  row['kaldi_text'],\n",
    "                                                                  row['kaldi_confids']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few examples of phrase alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "story text:  he even called the other kids names and stole their snacks\n",
      "--- google:  from here so no one could swim he even called the other kids stage and stole their snacks all the kids\n",
      "--- scores for aligned words:  {'he': 0.9, 'even': 0.9, 'called': 0.9, 'the': 0.9, 'other': 0.9, 'kids': 0.9, 'names': -0.9, 'and': 0.9, 'stole': 0.9, 'their': 0.9, 'snacks': 0.9}\n",
      "                 -----------------------               \n",
      "@@@@ amazon:  huh street from here so does a wad kind sweet he even called the other kids daves installed their stacks all the kids\n",
      "@@@@ scores for aligned words:  {'he': 1.0, 'even': 1.0, 'called': 1.0, 'the': 1.0, 'other': 1.0, 'kids': 0.81, 'names': -0.73, 'and': -0.95, 'stole': -1.0, 'their': -1.0, 'snacks': -1.0}\n",
      "======================================================\n",
      "story text:  mary said recess should be like this every day\n",
      "--- google:  princess mary said reeses should be like this every day\n",
      "--- scores for aligned words:  {'mary': 0.73, 'said': 0.73, 'recess': -0.73, 'should': 0.73, 'be': 0.73, 'like': 0.73, 'this': 0.73, 'every': 0.73, 'day': 0.73}\n",
      "                 -----------------------               \n",
      "@@@@ amazon:  recess mary said recess should be like this every day\n",
      "@@@@ scores for aligned words:  {'mary': 0.84, 'said': 1.0, 'recess': 0.56, 'should': 1.0, 'be': 1.0, 'like': 1.0, 'this': 1.0, 'every': 0.93, 'day': 0.93}\n",
      "======================================================\n",
      "story text:  that day at recess mary and jason ran out to play\n",
      "--- google:  bad day at recess marion john and ran out to play\n",
      "--- scores for aligned words:  {'that': -0.87, 'day': 0.87, 'at': 0.87, 'recess': 0.87, 'mary': -0.87, 'and': -0.87, 'jason': -0.87, 'ran': 0.87, 'out': 0.87, 'to': 0.87, 'play': 0.87}\n",
      "                 -----------------------               \n",
      "@@@@ amazon:  that day at recess mary and draw and ran out to play\n",
      "@@@@ scores for aligned words:  {'that': 1.0, 'day': 1.0, 'at': 1.0, 'recess': 1.0, 'mary': 0.69, 'and': 1.0, 'jason': -1.0, 'ran': 1.0, 'out': 1.0, 'to': 1.0, 'play': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for k in [111, 222, 333]:\n",
    "    print('======================================================')\n",
    "    print('story text: ', act_df.loc[k]['expected text'])\n",
    "    print('--- google: ', act_df.loc[k]['google_output'])\n",
    "    print('--- scores for aligned words: ',act_df.loc[k]['google_scores'])\n",
    "    print('                 -----------------------               ')\n",
    "    print('@@@@ amazon: ', act_df.loc[k]['amazon_transcript'])\n",
    "    print('@@@@ scores for aligned words: ', act_df.loc[k]['amazon_scores'])\n",
    "#     print('                 -----------------------               ')\n",
    "#     print('+++ kaldi: ', act_df.loc[k]['kaldi_text'])\n",
    "#     print('+++ scores for aligned words: ', act_df.loc[k]['kaldi_scores'])\n",
    "#     print('                 -----------------------               ')\n",
    "#     print('#### pocketsphinx: ', act_df.loc[k]['pocketsphinx_transcript'])\n",
    "#     print('#### scores for aligned words: ',act_df.loc[k]['pocketsphinx_scores'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new dataframe containing word-level asr predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activityId</th>\n",
       "      <th>word</th>\n",
       "      <th>kaldi_score</th>\n",
       "      <th>google_score</th>\n",
       "      <th>amazon_score</th>\n",
       "      <th>pocketsphinx_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>every</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>day</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>during</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>recess</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>mary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     activityId    word kaldi_score google_score  \\\n",
       "0  017CDA554B3311E9BEA916071609   every           1           -4   \n",
       "1  017CDA554B3311E9BEA916071609     day           1         -0.9   \n",
       "2  017CDA554B3311E9BEA916071609  during           1          0.9   \n",
       "3  017CDA554B3311E9BEA916071609  recess        0.99          0.9   \n",
       "4  017CDA554B3311E9BEA916071609    mary           1          0.9   \n",
       "\n",
       "   amazon_score pocketsphinx_score  \n",
       "0          0.80                  1  \n",
       "1          0.80                  1  \n",
       "2          1.00                  1  \n",
       "3          0.98                  1  \n",
       "4          0.82                  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame(columns=['activityId', 'word', 'kaldi_score', 'google_score', 'amazon_score', 'pocketsphinx_score'])\n",
    "for index, row in act_df.iterrows():\n",
    "    words = row['kaldi_scores'].keys()\n",
    "    for w in words:\n",
    "        wrow = [row['activityId'], w, row['kaldi_scores'][w],\n",
    "                row['google_scores'][w], row['amazon_scores'][w], row['pocketsphinx_scores'][w]]\n",
    "        words_df.loc[len(words_df)] = wrow\n",
    "\n",
    "# standardize activityIDs:\n",
    "words_df['activityId'] = words_df['activityId'].apply(lambda x: x[:-4])\n",
    "utt_df['activityId'] = utt_df['activityId'].apply(lambda x: x[:-4])\n",
    "\n",
    "words_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels for classification task:\n",
    "For each unique `activityId`, we align the seqeuence of words from human annotation csv file (`utt_df`) to the expected list of words taken from `expected test` field. Given that most of words are correctly pronounces, the alignment implicitly aiging the errors too. We can then compare word by word, and take the ones that do not match as errors. \n",
    "We discard extra words introduced by human annotators (insertions) as they do not seem to be relevant to our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial dummy values\n",
    "words_df['label'] = True\n",
    "words_df['annotated_word'] = \"\"\n",
    "words_df['extra_annotated_word'] = \"\"\n",
    "\n",
    "unique_activity_ids = words_df.activityId.unique()\n",
    "\n",
    "# convert dataframes to records, for sequence alignment\n",
    "utt_recs = utt_df.to_dict('records')\n",
    "words_recs = words_df.to_dict('records')\n",
    "\n",
    "def edit_test(a,b):\n",
    "    \"\"\"\n",
    "    this function is used to overried the \"==\" operator for sequence matching.\n",
    "    Apart from the basic definition of equality(a==b), a loose notion of equality\n",
    "    is also used, so that partial word matches can also be aligned. Few example\n",
    "    pairs of partial matches: ('name', 'names'), ('book','ababcbook'), ....\n",
    "    \n",
    "    Inputs:\n",
    "        a,b (str): to string to be compared. Returns True if they match.\n",
    "    \"\"\"\n",
    "    loose_criteria = ((b[:-1] in a) or (a[:-1] in b)) and len(a) > 3 and len(b) > 3\n",
    "    if a==b or a in b or b in a or loose_criteria:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for id in unique_activity_ids:\n",
    "    # take list of all annotated words for this id. Remove blank \"   \"s.\n",
    "    annotator_words = [x['Utterance'] for x in utt_recs if x['activityId'] == id]\n",
    "    annotator_words = [w for w in annotator_words if len(w.replace(' ', '')) > 0]\n",
    "    \n",
    "    # take all expected words for current id\n",
    "    ref_words = [x['word'] for x in words_recs if x['activityId'] == id]\n",
    "    \n",
    "    # perform a loose sequence matching\n",
    "    sm = edit_distance.SequenceMatcher(ref_words,  annotator_words, test = edit_test)\n",
    "    opcodes = sm.get_opcodes()\n",
    "    \n",
    "    # the begining index in the original dataframe, to offset thw opcodes\n",
    "    beg_index = words_df[words_df['activityId'] == id].index[0]\n",
    "    \n",
    "    for op in opcodes:\n",
    "        if op[0] == 'equal':\n",
    "            words_df.loc[beg_index + op[1], 'annotated_word'] = annotator_words[op[3]]\n",
    "            if ref_words[op[1]] == annotator_words[op[3]]:\n",
    "                words_df.loc[beg_index + op[1], 'label'] = 'correct'\n",
    "            else:\n",
    "                words_df.loc[beg_index + op[1], 'label'] = 'error'\n",
    "        elif op[0] == 'replace':\n",
    "            if 'abc' in annotator_words[op[3]]:\n",
    "                words_df.loc[beg_index + op[1], 'label'] = 'error'\n",
    "            else:\n",
    "                words_df.loc[beg_index + op[1], 'label'] = 'error'\n",
    "            words_df.loc[beg_index + op[1], 'annotated_word'] = annotator_words[op[3]]\n",
    "        elif op[0] == 'insert':\n",
    "            words_df.loc[beg_index + op[1], 'extra_annotated_word'] = annotator_words[op[3]]\n",
    "        else:\n",
    "            words_df.loc[beg_index + op[1], 'annotated_word'] = \"\"\n",
    "            words_df.loc[beg_index + op[1], 'label'] = \"del\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activityId</th>\n",
       "      <th>word</th>\n",
       "      <th>kaldi_score</th>\n",
       "      <th>google_score</th>\n",
       "      <th>amazon_score</th>\n",
       "      <th>pocketsphinx_score</th>\n",
       "      <th>label</th>\n",
       "      <th>annotated_word</th>\n",
       "      <th>extra_annotated_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>every</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>every</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>day</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>day</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>during</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>during</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>recess</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>recess</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>mary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>mary</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>jason</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>jason</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>their</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>their</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>classmates</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>classmates</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>played</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>played</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>together</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>together</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>adam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>didnt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>didnt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>play</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>play</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>with</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>anybody</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>anybody</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>instead</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>instead</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>he</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>he</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>tossed</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>tossed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>playground</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>playground</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>balls</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>balls</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>over</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>fence</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>fence</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>threw</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>threw</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>swings</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>swings</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>up</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>up</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>swing</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>swing</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>set</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>set</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>bars</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>bars</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>so</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>no</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>one</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>could</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>could</td>\n",
       "      <td>swing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>he</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>he</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>even</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>even</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>called</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>called</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>other</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>kids</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>kids</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>names</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>error</td>\n",
       "      <td>abcabcname</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>and</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>and</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>stole</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>stole</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>their</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>their</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>snacks</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>snacks</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>kids</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>kids</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>at</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>school</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>school</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>were</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>were</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>afraid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>afraid</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>him</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>him</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>one</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>friday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>friday</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>adam</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>missed</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>missed</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>017CDA554B3311E9BEA916071609</td>\n",
       "      <td>school</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>school</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      activityId        word kaldi_score google_score  \\\n",
       "0   017CDA554B3311E9BEA916071609       every           1           -4   \n",
       "1   017CDA554B3311E9BEA916071609         day           1         -0.9   \n",
       "2   017CDA554B3311E9BEA916071609      during           1          0.9   \n",
       "3   017CDA554B3311E9BEA916071609      recess        0.99          0.9   \n",
       "4   017CDA554B3311E9BEA916071609        mary           1          0.9   \n",
       "5   017CDA554B3311E9BEA916071609       jason           1          0.9   \n",
       "6   017CDA554B3311E9BEA916071609         and           1          0.9   \n",
       "7   017CDA554B3311E9BEA916071609       their           1          0.9   \n",
       "8   017CDA554B3311E9BEA916071609  classmates           1          0.9   \n",
       "9   017CDA554B3311E9BEA916071609      played           1         -0.9   \n",
       "10  017CDA554B3311E9BEA916071609    together           1          0.9   \n",
       "11  017CDA554B3311E9BEA916071609        adam           1         0.97   \n",
       "12  017CDA554B3311E9BEA916071609       didnt           1         0.97   \n",
       "13  017CDA554B3311E9BEA916071609        play           1         0.97   \n",
       "14  017CDA554B3311E9BEA916071609        with           1         0.97   \n",
       "15  017CDA554B3311E9BEA916071609     anybody        0.93         0.97   \n",
       "16  017CDA554B3311E9BEA916071609     instead           1         0.96   \n",
       "17  017CDA554B3311E9BEA916071609          he           1         0.96   \n",
       "18  017CDA554B3311E9BEA916071609      tossed           1         0.96   \n",
       "19  017CDA554B3311E9BEA916071609         the           1          0.9   \n",
       "20  017CDA554B3311E9BEA916071609  playground           1         0.96   \n",
       "21  017CDA554B3311E9BEA916071609       balls           1         0.96   \n",
       "22  017CDA554B3311E9BEA916071609        over           1          0.9   \n",
       "23  017CDA554B3311E9BEA916071609       fence           1         0.96   \n",
       "24  017CDA554B3311E9BEA916071609         and           1         0.96   \n",
       "25  017CDA554B3311E9BEA916071609       threw           1        -0.96   \n",
       "26  017CDA554B3311E9BEA916071609      swings           1         0.96   \n",
       "27  017CDA554B3311E9BEA916071609          up           1          0.9   \n",
       "28  017CDA554B3311E9BEA916071609       swing        0.94          0.9   \n",
       "29  017CDA554B3311E9BEA916071609         set           1          0.9   \n",
       "30  017CDA554B3311E9BEA916071609        bars           1          0.9   \n",
       "31  017CDA554B3311E9BEA916071609          so           1          0.9   \n",
       "32  017CDA554B3311E9BEA916071609          no           1          0.9   \n",
       "33  017CDA554B3311E9BEA916071609         one           1          0.9   \n",
       "34  017CDA554B3311E9BEA916071609       could           1          0.9   \n",
       "35  017CDA554B3311E9BEA916071609          he           1        -0.96   \n",
       "36  017CDA554B3311E9BEA916071609        even           1         0.96   \n",
       "37  017CDA554B3311E9BEA916071609      called           1         0.96   \n",
       "38  017CDA554B3311E9BEA916071609         the           1         0.96   \n",
       "39  017CDA554B3311E9BEA916071609       other           1         0.96   \n",
       "40  017CDA554B3311E9BEA916071609        kids           1         0.96   \n",
       "41  017CDA554B3311E9BEA916071609       names       -0.75        -0.96   \n",
       "42  017CDA554B3311E9BEA916071609         and        0.99         0.96   \n",
       "43  017CDA554B3311E9BEA916071609       stole           1        -0.96   \n",
       "44  017CDA554B3311E9BEA916071609       their           1         0.96   \n",
       "45  017CDA554B3311E9BEA916071609      snacks           1         0.96   \n",
       "46  017CDA554B3311E9BEA916071609         all           1          0.9   \n",
       "47  017CDA554B3311E9BEA916071609         the           1          0.9   \n",
       "48  017CDA554B3311E9BEA916071609        kids           1          0.9   \n",
       "49  017CDA554B3311E9BEA916071609          at           1          0.9   \n",
       "50  017CDA554B3311E9BEA916071609      school           1          0.9   \n",
       "51  017CDA554B3311E9BEA916071609        were           1          0.9   \n",
       "52  017CDA554B3311E9BEA916071609      afraid           1          0.9   \n",
       "53  017CDA554B3311E9BEA916071609          of           1          0.9   \n",
       "54  017CDA554B3311E9BEA916071609         him        0.56          0.9   \n",
       "55  017CDA554B3311E9BEA916071609         one           1          0.8   \n",
       "56  017CDA554B3311E9BEA916071609      friday           1          0.8   \n",
       "57  017CDA554B3311E9BEA916071609        adam           1         -0.8   \n",
       "58  017CDA554B3311E9BEA916071609      missed           1         -0.8   \n",
       "59  017CDA554B3311E9BEA916071609      school           1          0.8   \n",
       "\n",
       "    amazon_score pocketsphinx_score    label annotated_word  \\\n",
       "0           0.80                  1  correct          every   \n",
       "1           0.80                  1  correct            day   \n",
       "2           1.00                  1  correct         during   \n",
       "3           0.98                  1  correct         recess   \n",
       "4           0.82                  1  correct           mary   \n",
       "5           1.00                  1  correct          jason   \n",
       "6           1.00                  1  correct            and   \n",
       "7           0.97                  1  correct          their   \n",
       "8           1.00                  1  correct     classmates   \n",
       "9           0.97                  1  correct         played   \n",
       "10          1.00                  1  correct       together   \n",
       "11          1.00                  1  correct           adam   \n",
       "12          0.99                  1  correct          didnt   \n",
       "13          1.00                  1  correct           play   \n",
       "14          1.00                  1  correct           with   \n",
       "15          1.00                  1  correct        anybody   \n",
       "16          1.00                  1  correct        instead   \n",
       "17          1.00                  1  correct             he   \n",
       "18          1.00                  1  correct         tossed   \n",
       "19          1.00                  1  correct            the   \n",
       "20          0.85                  1  correct     playground   \n",
       "21          1.00                  1  correct          balls   \n",
       "22          1.00                  1  correct           over   \n",
       "23          1.00                  1  correct          fence   \n",
       "24          1.00                  1  correct            and   \n",
       "25         -0.70                  1  correct          threw   \n",
       "26          0.95                  1  correct         swings   \n",
       "27          1.00                  1  correct             up   \n",
       "28          1.00                  1  correct          swing   \n",
       "29          0.99                  1  correct            set   \n",
       "30          0.96                  1  correct           bars   \n",
       "31          1.00                  1  correct             so   \n",
       "32          1.00                  1  correct             no   \n",
       "33          1.00                  1  correct            one   \n",
       "34          1.00                  1  correct          could   \n",
       "35          1.00                  1  correct             he   \n",
       "36          1.00                  1  correct           even   \n",
       "37          1.00                  1  correct         called   \n",
       "38          1.00                  1  correct            the   \n",
       "39          1.00                  1  correct          other   \n",
       "40          0.94                  1  correct           kids   \n",
       "41         -4.00                  1    error     abcabcname   \n",
       "42         -1.00                  1  correct            and   \n",
       "43         -0.67                  1  correct          stole   \n",
       "44          0.77                  1  correct          their   \n",
       "45          1.00                  1  correct         snacks   \n",
       "46          1.00                  1  correct            all   \n",
       "47          1.00                  1  correct            the   \n",
       "48          1.00                  1  correct           kids   \n",
       "49          1.00                  1  correct             at   \n",
       "50          1.00                  1  correct         school   \n",
       "51          1.00                  1  correct           were   \n",
       "52          1.00                  1  correct         afraid   \n",
       "53          1.00                  1  correct             of   \n",
       "54          1.00                  1  correct            him   \n",
       "55          0.98                  1  correct            one   \n",
       "56          1.00                  1  correct         friday   \n",
       "57          0.99                  1  correct           adam   \n",
       "58         -1.00                  1  correct         missed   \n",
       "59          1.00                  1  correct         school   \n",
       "\n",
       "   extra_annotated_word  \n",
       "0                        \n",
       "1                        \n",
       "2                        \n",
       "3                        \n",
       "4                        \n",
       "5                        \n",
       "6                        \n",
       "7                        \n",
       "8                        \n",
       "9                        \n",
       "10                       \n",
       "11                       \n",
       "12                       \n",
       "13                       \n",
       "14                       \n",
       "15                       \n",
       "16                       \n",
       "17                       \n",
       "18                       \n",
       "19                       \n",
       "20                       \n",
       "21                       \n",
       "22                  the  \n",
       "23                       \n",
       "24                       \n",
       "25                  the  \n",
       "26                       \n",
       "27                  the  \n",
       "28                       \n",
       "29                       \n",
       "30                       \n",
       "31                       \n",
       "32                       \n",
       "33                       \n",
       "34                swing  \n",
       "35                       \n",
       "36                       \n",
       "37                       \n",
       "38                       \n",
       "39                       \n",
       "40                       \n",
       "41                       \n",
       "42                       \n",
       "43                       \n",
       "44                       \n",
       "45                       \n",
       "46                       \n",
       "47                       \n",
       "48                       \n",
       "49                       \n",
       "50                       \n",
       "51                       \n",
       "52                       \n",
       "53                       \n",
       "54                       \n",
       "55                       \n",
       "56                       \n",
       "57                       \n",
       "58                       \n",
       "59                       "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature exploration:\n",
    "No that we have a complete dataset, we can analyze the data to get some intuition about how we can build a model. Lets look at the distribution of scores, for the three label categories: `error`, `correct` and `del`. Note that densities are plotted instead of simple histogram so that the much more frequent `correct` class would not dominate the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = words_df.label.unique()\n",
    "scores = ['kaldi_score', 'google_score', 'amazon_score','pocketsphinx_score']\n",
    "\n",
    "for sc in scores:\n",
    "    plt.hist([words_df.loc[words_df.label == x, sc] for x in categories],\n",
    "             label=categories, density=True, bins = 10)\n",
    "    plt.legend()\n",
    "    plt.title(sc)\n",
    "    plt.ylabel('probability density function')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots, it can be seen that the scores can indeed be useful for the classification task at hand. Most of the `correct` words have higher confidence values around `1`, while the `errors` seem to be having lower, and even negative, values of confidence. The `deletion` cases have also got the extreme negative value assigned to them during data preparation (`-4`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and testing dataset splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kaldi_score</th>\n",
       "      <th>google_score</th>\n",
       "      <th>amazon_score</th>\n",
       "      <th>pocketsphinx_score</th>\n",
       "      <th>label</th>\n",
       "      <th>n_asr_del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15349</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16716</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23869</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21078</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23646</th>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22811</th>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20111</th>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>error</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>1</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16519</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19065</th>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19540</th>\n",
       "      <td>-1</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>del</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18033</th>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19066</th>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>del</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21178</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8339</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5669</th>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>correct</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kaldi_score google_score  amazon_score pocketsphinx_score    label  \\\n",
       "2579            1         0.94          1.00                  1  correct   \n",
       "15349           1         0.93          1.00                  1  correct   \n",
       "16716           1         0.93          1.00                  1  correct   \n",
       "23869           1         0.93          1.00                  1  correct   \n",
       "21078           1          0.9          1.00                  1  correct   \n",
       "14693           1         0.94          1.00                  1  correct   \n",
       "23646           1         0.79          1.00                  1  correct   \n",
       "3510            1         0.94          1.00                  1  correct   \n",
       "22811           1         0.93          0.98                 -1  correct   \n",
       "3346            1         0.89         -1.00                  1  correct   \n",
       "20111           1         0.82         -0.99                  1    error   \n",
       "4976            1         0.94          1.00                  1  correct   \n",
       "11140           1        -0.89          1.00                  1  correct   \n",
       "762             1         0.91          1.00                  1  correct   \n",
       "6195            1         0.88          1.00                  1  correct   \n",
       "16519           1         0.98          1.00                  1  correct   \n",
       "1013            1        -0.81         -0.76                  1  correct   \n",
       "21622           1         0.87          1.00                  1  correct   \n",
       "3919            1          0.9          0.92                  1  correct   \n",
       "19065       -0.97         0.92          1.00                  1  correct   \n",
       "19540          -1        -0.93         -1.00                  1      del   \n",
       "18033           1         0.81          0.99                  1  correct   \n",
       "839             1         0.94          1.00                  1  correct   \n",
       "8807            1         0.87          1.00                  1  correct   \n",
       "3237            1         0.83          1.00                  1  correct   \n",
       "19066           1         0.92          1.00                  1  correct   \n",
       "18450        -0.8        -0.84         -1.00                 -1      del   \n",
       "21178           1        -0.92          1.00                  1  correct   \n",
       "8339            1         0.85          0.89                  1  correct   \n",
       "5669            1         0.94          1.00                  1  correct   \n",
       "\n",
       "       n_asr_del  \n",
       "2579           0  \n",
       "15349          0  \n",
       "16716          0  \n",
       "23869          0  \n",
       "21078          0  \n",
       "14693          0  \n",
       "23646          0  \n",
       "3510           0  \n",
       "22811          0  \n",
       "3346           0  \n",
       "20111          0  \n",
       "4976           0  \n",
       "11140          0  \n",
       "762            0  \n",
       "6195           0  \n",
       "16519          0  \n",
       "1013           0  \n",
       "21622          0  \n",
       "3919           0  \n",
       "19065          0  \n",
       "19540          0  \n",
       "18033          0  \n",
       "839            0  \n",
       "8807           0  \n",
       "3237           0  \n",
       "19066          0  \n",
       "18450          0  \n",
       "21178          0  \n",
       "8339           0  \n",
       "5669           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORES = ['kaldi_score', 'google_score', 'amazon_score', 'pocketsphinx_score']\n",
    "dataset_df = words_df[SCORES + ['label']].copy()\n",
    "dataset_df['n_asr_del'] = 0\n",
    "for sc in SCORES:\n",
    "    # for each ASR score < -3, count one deletion\n",
    "    dataset_df['n_asr_del'] = dataset_df.apply(lambda r: r['n_asr_del'] + 1 if r[sc] < -3 else r['n_asr_del'],\n",
    "                                               axis=1)\n",
    "    # clip deletion values of -4 to -1, so that they are just an error, not having a large negative value\n",
    "    dataset_df[sc] = dataset_df[sc].clip(-1, 1)\n",
    "df_train, df_test = train_test_split(dataset_df,stratify=words_df['label'], test_size=0.15)\n",
    "df_train.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-based approach\n",
    "As a first attempt, we can try to implement a simple rule-based majority voting based approach.\n",
    "For each word, if the majority of confidence scores were above a thershold, we take them as `correct`ly detected. The thresholds for each ASR system are automatically computed as 20% percentile of each score. \n",
    "Given that in the score generation step, we assigned the extreme negative value of -4 to the deleted words, the second rule counts such cases and if the majority of ASR systems had detected a deletion, we classify as a `del`etion. All other words that are neither correctely detected nor deleted are considered as `error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Train set accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.98      0.96      0.97     18678\n",
      "         del       0.81      0.48      0.60      1425\n",
      "       error       0.25      0.61      0.35       722\n",
      "\n",
      "    accuracy                           0.91     20825\n",
      "   macro avg       0.68      0.68      0.64     20825\n",
      "weighted avg       0.94      0.91      0.92     20825\n",
      "\n",
      "confusion matrix:\n",
      " [[17853    82   743]\n",
      " [  128   686   611]\n",
      " [  198    83   441]]\n",
      "------------------ Test set accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.98      0.96      0.97      3296\n",
      "         del       0.82      0.52      0.64       251\n",
      "       error       0.28      0.69      0.40       128\n",
      "\n",
      "    accuracy                           0.92      3675\n",
      "   macro avg       0.70      0.72      0.67      3675\n",
      "weighted avg       0.95      0.92      0.93      3675\n",
      "\n",
      "confusion matrix:\n",
      "  [[3149   15  132]\n",
      " [  26  131   94]\n",
      " [  27   13   88]]\n"
     ]
    }
   ],
   "source": [
    "def classify(row_dict, sc_th):\n",
    "    \"\"\"\n",
    "    A rule-based majority-voting classifier, that for every key in row_dict\n",
    "    uses the corresponding thresold in the sc_th dictionary and counts the number \n",
    "    of deletions and correct detections. Based on these counts, the final classification\n",
    "    if performed.\n",
    "    \n",
    "    Returns: One of the three labels: 'error', 'del', 'correct'\n",
    "    \"\"\"\n",
    "    n_correct = 0\n",
    "    n_del = 0\n",
    "    for sc in SCORES:\n",
    "        if row_dict[sc] > sc_th[sc]:\n",
    "            n_correct += 1\n",
    "        elif row_dict[sc] < - 3.5:\n",
    "            n_del += 1\n",
    "    if n_correct >= 2:\n",
    "        return \"correct\"\n",
    "    elif row_dict['n_asr_del'] >= 2:\n",
    "        return \"del\"\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "# automated generation of thresholds form the training dataset\n",
    "percentile_th = 0.2\n",
    "margin = 0.01\n",
    "sc_correct_th = {}\n",
    "for sc in SCORES:\n",
    "    sc_correct_th[sc] = df_train[df_train['label']=='correct'][sc].quantile(percentile_th) - margin\n",
    "\n",
    "# lets test the classifier first on train set (for parameter tunning maybe)\n",
    "print('------------------ Train set accuracy:')\n",
    "prediction = df_train.apply(lambda r: classify(r, sc_correct_th), axis=1)\n",
    "print(classification_report(df_train['label'], prediction))\n",
    "print('confusion matrix:\\n', confusion_matrix(df_train['label'], prediction))\n",
    "\n",
    "# After parameter tunning measure the performance on the test set.\n",
    "print('------------------ Test set accuracy:')\n",
    "prediction = df_test.apply(lambda r: classify(r, sc_correct_th), axis=1)\n",
    "print(classification_report(df_test['label'], prediction))\n",
    "print('confusion matrix:\\n ', confusion_matrix(df_test['label'], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set accuracies are not too bad. Specially that the recall value for the target class is high (`0.63`). The low precision is partly due to the `error` --> `del` type of errors. If we take a deletion as an error, the accuracy will be much higher. We will see this at the end of these experiments. Bur for now lets try few other simple classifiers. \n",
    "### Random Forest clasisfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Test set accuracy:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.98      0.98      0.98      3296\n",
      "         del       0.84      0.55      0.66       251\n",
      "       error       0.35      0.59      0.44       128\n",
      "\n",
      "    accuracy                           0.94      3675\n",
      "   macro avg       0.72      0.70      0.69      3675\n",
      "weighted avg       0.95      0.94      0.94      3675\n",
      "\n",
      "[[3228   12   56]\n",
      " [  33  137   81]\n",
      " [  39   14   75]]\n"
     ]
    }
   ],
   "source": [
    "X = df_train[SCORES + ['n_asr_del']]\n",
    "y = df_train['label']\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5,\n",
    "                             random_state=0, class_weight={'correct':0.2,\n",
    "                                                           'del':0.2,\n",
    "                                                           'error':0.8})\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(df_test[SCORES+ ['n_asr_del']])\n",
    "print('------------------ Test set accuracy:')\n",
    "print(classification_report(df_test['label'], y_pred))\n",
    "print(confusion_matrix(df_test['label'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest slightly improved the results. But we still observe the same trend of `error` --> `del` type of error.\n",
    "\n",
    "### Logistic Regression classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.98      0.98      0.98      3296\n",
      "         del       0.83      0.42      0.56       251\n",
      "       error       0.29      0.59      0.39       128\n",
      "\n",
      "    accuracy                           0.92      3675\n",
      "   macro avg       0.70      0.66      0.64      3675\n",
      "weighted avg       0.94      0.92      0.93      3675\n",
      "\n",
      "[[3216   10   70]\n",
      " [  34  105  112]\n",
      " [  41   12   75]]\n",
      "LR coefficients:  [[ 0.8894044   0.62931467  0.66542245  0.26383234 -0.05224864]\n",
      " [-0.57551363 -0.28250031 -0.3241548  -0.20877452  0.31194678]\n",
      " [-0.31389077 -0.34681436 -0.34126764 -0.05505782 -0.25969813]]\n"
     ]
    }
   ],
   "source": [
    "X = df_train[SCORES + ['n_asr_del']]\n",
    "y = df_train['label']\n",
    "clf = LogisticRegression(random_state=0, class_weight={'correct':0.2,\n",
    "                                                       'del':0.2,\n",
    "                                                       'error':.9})\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(df_test[SCORES+ ['n_asr_del']])\n",
    "print(classification_report(df_test['label'], y_pred))\n",
    "print(confusion_matrix(df_test['label'], y_pred))\n",
    "print('LR coefficients: ', clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of Logistic Regression classifier is very close to the Random forest one. Lets focus on `error` --> `del` type of error, by mapping all instances of `del` to `error`, and retrain our best classifier.\n",
    "\n",
    "### Two-class Random Forest classifer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct       0.98      0.97      0.97      3296\n",
      "       error       0.74      0.85      0.79       379\n",
      "\n",
      "    accuracy                           0.95      3675\n",
      "   macro avg       0.86      0.91      0.88      3675\n",
      "weighted avg       0.96      0.95      0.96      3675\n",
      "\n",
      "[[3183  113]\n",
      " [  56  323]]\n"
     ]
    }
   ],
   "source": [
    "X = df_train[SCORES + ['n_asr_del']]\n",
    "y = df_train['label'].copy()\n",
    "# convert all `del` labels to `error`\n",
    "y[y=='del']='error'\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5,\n",
    "                             random_state=0, class_weight={'correct':0.2,\n",
    "                                                           'error':0.8})\n",
    "clf.fit(X, y)\n",
    "y_test = df_test['label'].copy()\n",
    "y_test[y_test=='del']='error'\n",
    "y_pred = clf.predict(df_test[SCORES+ ['n_asr_del']])\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the performance is significantly improved by merging the two classes `del` and `error`. This suggests that:\n",
    "- Our data preparation could be revisited, making sure that we are not labeling errors as deletions.\n",
    "- The annotators might not have entered a word for some errors. In this case, the ASR systems generate a low-confidence output (as in an error), but the label generated from human annotation is `del` because the word is missing.\n",
    "\n",
    "This certainly necessiated further data analysis to understand and probably debug the current data preparation operations.\n",
    "\n",
    "\n",
    "\n",
    "### Future work:\n",
    "- revisit data preparation steps, deeg deeper to remove any erroneous labels from the dataset\n",
    "- in-depth error analysis to understand the trends and potential errors\n",
    "- get a better understanding about the 4 different ASR systems, how they are trained and what datasets are used for training them.\n",
    "- literature review/peer discussion to understand prior works\n",
    "- parameter tunning and grid search for the classifiers\n",
    "- consider alternative approaches, such as training a phonetic recognizer rather than an LM backed ASR system. An e2e phonetic recognizer will require phone-level pattern matching which is a challenging task and prone to error in absence of an LM. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_stock)",
   "language": "python",
   "name": "conda_stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
